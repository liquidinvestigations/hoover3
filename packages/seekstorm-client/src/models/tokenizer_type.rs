/*
 * SeekStorm REST API documentation
 *
 * Search engine library & multi-tenancy server
 *
 * The version of the OpenAPI document: 0.12.11
 * Contact: wolf.garbe@seekstorm.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// TokenizerType : Defines tokenizer behavior:  AsciiAlphabetic - Mainly for for benchmark compatibility - Only ASCII alphabetic chars are recognized as token.  UnicodeAlphanumeric - All Unicode alphanumeric chars are recognized as token. - Allows '+' '-' '#' in middle or end of a token: c++, c#, block-max.  UnicodeAlphanumericFolded - All Unicode alphanumeric chars are recognized as token. - Allows '+' '-' '#' in middle or end of a token: c++, c#, block-max. - Diacritics, accents, zalgo text, umlaut, bold, italic, full-width UTF-8 characters are converted into its basic representation. - Apostroph handling prevents that short term parts preceding or following the apostroph get indexed (e.g. \"s\" in \"someone's\"). - Tokenizing might be slower due to folding and apostroph processing.  UnicodeAlphanumericZH - Implements Chinese word segmentation to segment continuous Chinese text into tokens for indexing and search. - Supports mixed Latin and Chinese texts - Supports Chinese sentence boundary chars for KWIC snippets ahd highlighting. - Requires feature #[cfg(feature = \"zh\")]
/// Defines tokenizer behavior:  AsciiAlphabetic - Mainly for for benchmark compatibility - Only ASCII alphabetic chars are recognized as token.  UnicodeAlphanumeric - All Unicode alphanumeric chars are recognized as token. - Allows '+' '-' '#' in middle or end of a token: c++, c#, block-max.  UnicodeAlphanumericFolded - All Unicode alphanumeric chars are recognized as token. - Allows '+' '-' '#' in middle or end of a token: c++, c#, block-max. - Diacritics, accents, zalgo text, umlaut, bold, italic, full-width UTF-8 characters are converted into its basic representation. - Apostroph handling prevents that short term parts preceding or following the apostroph get indexed (e.g. \"s\" in \"someone's\"). - Tokenizing might be slower due to folding and apostroph processing.  UnicodeAlphanumericZH - Implements Chinese word segmentation to segment continuous Chinese text into tokens for indexing and search. - Supports mixed Latin and Chinese texts - Supports Chinese sentence boundary chars for KWIC snippets ahd highlighting. - Requires feature #[cfg(feature = \"zh\")]
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum TokenizerType {
    #[serde(rename = "AsciiAlphabetic")]
    AsciiAlphabetic,
    #[serde(rename = "UnicodeAlphanumeric")]
    UnicodeAlphanumeric,
    #[serde(rename = "UnicodeAlphanumericFolded")]
    UnicodeAlphanumericFolded,
    #[serde(rename = "UnicodeAlphanumericZH")]
    UnicodeAlphanumericZh,

}

impl std::fmt::Display for TokenizerType {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Self::AsciiAlphabetic => write!(f, "AsciiAlphabetic"),
            Self::UnicodeAlphanumeric => write!(f, "UnicodeAlphanumeric"),
            Self::UnicodeAlphanumericFolded => write!(f, "UnicodeAlphanumericFolded"),
            Self::UnicodeAlphanumericZh => write!(f, "UnicodeAlphanumericZH"),
        }
    }
}

impl Default for TokenizerType {
    fn default() -> TokenizerType {
        Self::AsciiAlphabetic
    }
}

